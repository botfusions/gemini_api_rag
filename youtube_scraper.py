"""
YouTube Kanal Video Ã‡ekme ModÃ¼lÃ¼
Apify kullanarak YouTube kanallarÄ±ndan video bilgilerini Ã§eker
"""

import os
from apify_client import ApifyClient
from dotenv import load_dotenv
import json
from datetime import datetime

# .env dosyasÄ±ndan Ã§evre deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()


class YouTubeScraper:
    def __init__(self):
        """Apify client'Ä± baÅŸlat"""
        api_key = os.getenv('APIFY_API_KEY')
        if not api_key:
            raise ValueError("APIFY_API_KEY bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")

        self.client = ApifyClient(api_key)

    def fetch_channel_videos(self, channel_url, max_videos=50):
        """
        Verilen YouTube kanal URL'sinden videolarÄ± Ã§ek

        Args:
            channel_url (str): YouTube kanal URL'si
            max_videos (int): Ã‡ekilecek maksimum video sayÄ±sÄ±

        Returns:
            list: Video bilgilerini iÃ§eren liste
        """
        print(f"ğŸ“º Kanal videolarÄ± Ã§ekiliyor: {channel_url}")

        # Apify YouTube Scraper actor'Ã¼nÃ¼ kullan
        # Actor ID: streamers/youtube-scraper
        run_input = {
            "startUrls": [{"url": channel_url}],
            "maxResults": max_videos,
            "searchType": "channel",
        }

        try:
            # Actor'Ã¼ Ã§alÄ±ÅŸtÄ±r
            run = self.client.actor("streamers/youtube-scraper").call(run_input=run_input)

            # SonuÃ§larÄ± al
            videos = []
            for item in self.client.dataset(run["defaultDatasetId"]).iterate_items():
                videos.append(item)

            # VideolarÄ± tarih sÄ±rasÄ±na gÃ¶re sÄ±rala (en yeni en baÅŸta)
            videos.sort(key=lambda x: x.get('publishedAt', ''), reverse=True)

            print(f"âœ… {len(videos)} video bulundu")
            return videos

        except Exception as e:
            print(f"âŒ Hata oluÅŸtu: {str(e)}")
            return []

    def fetch_video_transcript(self, video_url):
        """
        Verilen video URL'sinden altyazÄ±larÄ± Ã§ek

        Args:
            video_url (str): YouTube video URL'si

        Returns:
            str: Video altyazÄ± metni
        """
        print(f"ğŸ“ AltyazÄ± Ã§ekiliyor: {video_url}")

        # Apify YouTube Transcript Scraper actor'Ã¼nÃ¼ kullan
        run_input = {
            "startUrls": [{"url": video_url}],
        }

        try:
            # Actor'Ã¼ Ã§alÄ±ÅŸtÄ±r
            run = self.client.actor("streamers/youtube-scraper").call(run_input=run_input)

            # SonuÃ§larÄ± al
            for item in self.client.dataset(run["defaultDatasetId"]).iterate_items():
                # AltyazÄ± varsa dÃ¶ndÃ¼r
                if 'subtitles' in item and item['subtitles']:
                    transcript = ' '.join([sub.get('text', '') for sub in item['subtitles']])
                    print(f"âœ… AltyazÄ± bulundu ({len(transcript)} karakter)")
                    return transcript
                elif 'description' in item:
                    print("âš ï¸ AltyazÄ± bulunamadÄ±, aÃ§Ä±klama kullanÄ±lÄ±yor")
                    return item['description']

            print("âš ï¸ AltyazÄ± bulunamadÄ±")
            return ""

        except Exception as e:
            print(f"âŒ AltyazÄ± Ã§ekilirken hata: {str(e)}")
            return ""

    def save_video_data(self, video, transcript, output_dir="videos"):
        """
        Video bilgilerini ve altyazÄ±sÄ±nÄ± dosyaya kaydet

        Args:
            video (dict): Video bilgileri
            transcript (str): Video altyazÄ±sÄ±
            output_dir (str): Ã‡Ä±ktÄ± dizini

        Returns:
            str: OluÅŸturulan dosya yolu
        """
        # Ã‡Ä±ktÄ± dizinini oluÅŸtur
        os.makedirs(output_dir, exist_ok=True)

        # Dosya adÄ± oluÅŸtur (video ID kullan)
        video_id = video.get('id', 'unknown')
        filename = f"{video_id}.json"
        filepath = os.path.join(output_dir, filename)

        # Video verisini hazÄ±rla
        video_data = {
            'id': video.get('id', ''),
            'title': video.get('title', ''),
            'description': video.get('description', ''),
            'publishedAt': video.get('publishedAt', ''),
            'url': video.get('url', ''),
            'thumbnail': video.get('thumbnail', ''),
            'views': video.get('viewCount', 0),
            'likes': video.get('likeCount', 0),
            'duration': video.get('duration', ''),
            'transcript': transcript,
            'transcript_tr': '',  # Ã‡eviri iÃ§in boÅŸ bÄ±rak
        }

        # Dosyaya kaydet
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(video_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ Kaydedildi: {filepath}")
        return filepath


if __name__ == "__main__":
    # Test iÃ§in
    scraper = YouTubeScraper()

    # Ã–rnek kanal URL'si
    channel_url = input("YouTube kanal URL'sini girin: ")

    # VideolarÄ± Ã§ek
    videos = scraper.fetch_channel_videos(channel_url, max_videos=10)

    # Her video iÃ§in altyazÄ± Ã§ek ve kaydet
    for i, video in enumerate(videos, 1):
        print(f"\n[{i}/{len(videos)}] Ä°ÅŸleniyor: {video.get('title', 'Ä°simsiz')}")
        video_url = video.get('url', '')

        if video_url:
            transcript = scraper.fetch_video_transcript(video_url)
            scraper.save_video_data(video, transcript)

    print("\nâœ¨ TÃ¼m videolar iÅŸlendi!")
